# ğŸ—ï¸ System Architecture

Technical architecture and design documentation for Bielik Polish AI Assistant CLI.

## ğŸ“‹ **Navigation Menu**
- [ğŸ  Documentation Home](README.md)
- [ğŸ“¥ Installation](INSTALLATION.md)
- [âš¡ Usage Guide](USAGE.md)
- [ğŸ¤ Contributing](CONTRIBUTING.md)

---

## ğŸ¯ **System Overview**

Bielik is designed as a modular, extensible Polish AI assistant with three main interfaces: CLI, Python API, and Web Server. The system prioritizes local model execution for privacy and performance.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ¦… BIELIK SYSTEM                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ–¥ï¸  CLI Shell     â”‚  ğŸŒ FastAPI Server   â”‚  ğŸ³ Docker Tests   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Interactive   â”‚â”‚ â”‚ â€¢ REST /chat      â”‚ â”‚ â”‚ â€¢ Minimal     â”‚ â”‚
â”‚  â”‚ â€¢ Personalized  â”‚â”‚ â”‚ â€¢ WebSocket /ws   â”‚ â”‚ â”‚ â€¢ Full        â”‚ â”‚
â”‚  â”‚ â€¢ Multi-modal   â”‚â”‚ â”‚ â€¢ Port 8000       â”‚ â”‚ â”‚ â€¢ CI/CD       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                       â”‚                       â”‚
            â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸ¤— HUGGINGFACE INTEGRATION                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Direct Downloads   â”‚â—„â”€â”€â–ºâ”‚     Local Model Execution   â”‚  â”‚
â”‚  â”‚ â”Œâ”€ HF Hub API        â”‚    â”‚ â”Œâ”€ llama-cpp-python         â”‚  â”‚
â”‚  â”‚ â””â”€ Model Management  â”‚    â”‚ â””â”€ Vision Models (optional) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ğŸ“š POLISH LANGUAGE MODELS                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ¤– Speakleash/Bielik Models (HuggingFace Hub)           â”‚  â”‚
â”‚  â”‚ ğŸ”— Direct: HuggingFace â†’ Local Storage â†’ Execution      â”‚  â”‚
â”‚  â”‚ ğŸ¯ Polish-optimized conversation and analysis           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§± **Core Components**

### 1. **CLI Interface** (`bielik/cli/`)

**Purpose**: Primary user interface for Polish AI conversations

**Components:**
- `main.py` - Entry point, argument parsing, prompt execution
- `commands.py` - Built-in CLI commands (`:help`, `:models`, `:setup`)
- `command_api.py` - Context Provider Commands registry and execution
- `send_chat.py` - Chat communication with local models
- `models.py` - HuggingFace model management
- `setup.py` - Interactive system configuration

**Key Features:**
- âœ… Personalized user experience with names and settings
- âœ… Context Provider Commands (`folder:`, `calc:`, `pdf:`)
- âœ… Model management (download, switch, delete)
- âœ… Project-based artifact collection
- âœ… Multi-modal support (text + images)

### 2. **Python Client** (`bielik/client/`)

**Purpose**: Programmatic access to Bielik functionality

**Components:**
- `core.py` - Main BielikClient class
- `model_manager.py` - HuggingFace model operations
- `utils.py` - Utility functions and helpers

**Key Features:**
- âœ… Simple `chat()` and `query()` methods
- âœ… Automatic model management
- âœ… Conversation export functionality
- âœ… Status and configuration access

### 3. **Web Server** (`bielik/server.py`)

**Purpose**: REST API and WebSocket interface

**Endpoints:**
- `POST /chat` - JSON chat endpoint
- `WS /ws` - WebSocket real-time chat
- `GET /models` - List available models
- `GET /health` - Health check

### 4. **Context Provider Commands** (`commands/`)

**Purpose**: Extensible command system for data analysis

**Architecture:**
```
commands/
â”œâ”€â”€ folder/          # Directory analysis
â”‚   â”œâ”€â”€ main.py      # Implementation
â”‚   â””â”€â”€ config.json  # Metadata
â”œâ”€â”€ calc/           # Mathematical calculations
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ config.json
â””â”€â”€ pdf/           # Document processing
    â”œâ”€â”€ main.py
    â””â”€â”€ config.json
```

**Features:**
- âœ… Standardized `name:` command format
- âœ… Automatic registration and loading
- âœ… Independent operation (no AI model required)
- âœ… Structured context generation for AI analysis

---

## ğŸ”„ **Data Flow Architecture**

### **CLI Chat Flow**
```
User Input â†’ Prompt Processing â†’ Context Provider Check â†’ Model Loading â†’ Response Generation
     â†“              â†“                    â†“                    â†“              â†“
[bielik -p]    [main.py]         [command_api.py]     [local_runner.py]  [send_chat.py]
     â†“              â†“                    â†“                    â†“              â†“
  "calc: 2+3"  â†’ Parse command    â†’ Execute calc:     â†’ Skip (direct)    â†’ Return "5"
  "Hello"      â†’ Regular prompt   â†’ No command        â†’ Load model       â†’ AI response
```

### **Context Provider Flow**
```
Context Command â†’ Parse Arguments â†’ Execute Provider â†’ Generate Context â†’ Return Result
       â†“               â†“                   â†“                â†“              â†“
   "folder: ."    ["folder:", "."]    FolderCommand    File listing    Structured data
   "calc: 2+3"    ["calc:", "2+3"]    CalcCommand     Evaluation       "Result: 5"
   "pdf: doc.pdf" ["pdf:", "doc.pdf"] PdfCommand      Text extraction  Document content
```

### **Model Management Flow**
```
User Command â†’ HF Hub Check â†’ Download â†’ Local Storage â†’ Model Registration â†’ Switch Active
     â†“              â†“            â†“           â†“                â†“                  â†“
:download model â†’ API call â†’ .safetensors  ~/.cache/    model_registry.json  Update .env
```

---

## ğŸ›ï¸ **Package Structure**

```
bielik/
â”œâ”€â”€ bielik/                      # Main package
â”‚   â”œâ”€â”€ __init__.py             # Package exports
â”‚   â”œâ”€â”€ cli.py                  # CLI entry point wrapper
â”‚   â”œâ”€â”€ client.py               # Client API wrapper
â”‚   â”œâ”€â”€ server.py               # FastAPI web server
â”‚   â”œâ”€â”€ config.py               # Configuration management
â”‚   â”œâ”€â”€ content_processor.py    # Content analysis utilities
â”‚   â”œâ”€â”€ cli/                    # Modular CLI components
â”‚   â”‚   â”œâ”€â”€ main.py            # Main CLI logic
â”‚   â”‚   â”œâ”€â”€ commands.py        # Built-in commands
â”‚   â”‚   â”œâ”€â”€ command_api.py     # Context Provider API
â”‚   â”‚   â”œâ”€â”€ models.py          # Model management
â”‚   â”‚   â”œâ”€â”€ setup.py           # Interactive setup
â”‚   â”‚   â””â”€â”€ send_chat.py       # Chat communication
â”‚   â”œâ”€â”€ client/                 # Client API components
â”‚   â”‚   â”œâ”€â”€ core.py            # BielikClient class
â”‚   â”‚   â”œâ”€â”€ model_manager.py   # Model operations
â”‚   â”‚   â””â”€â”€ utils.py           # Utilities
â”‚   â””â”€â”€ models/                 # Model execution
â”‚       â”œâ”€â”€ model_manager.py   # Local model management
â”‚       â””â”€â”€ local_runner.py    # llama-cpp-python interface
â”œâ”€â”€ commands/                   # Context Provider Commands
â”‚   â”œâ”€â”€ folder/                 # Directory analysis
â”‚   â”œâ”€â”€ calc/                   # Calculator
â”‚   â””â”€â”€ pdf/                    # Document processing
â”œâ”€â”€ docker/                     # Docker testing framework
â”œâ”€â”€ scripts/                    # Utility scripts
â””â”€â”€ tests/                      # Unit tests
```

---

## ğŸ”§ **Technical Specifications**

### **Core Dependencies**
- **Python 3.11+** - Modern Python features and performance
- **llama-cpp-python** - Local model execution (CPU/GPU)
- **huggingface-hub** - Model downloads and management
- **typer** - CLI framework with rich features
- **rich** - Beautiful terminal output
- **fastapi** - Web server framework
- **uvicorn** - ASGI server

### **Optional Dependencies**
- **transformers** - Vision model support
- **torch** - GPU acceleration
- **PIL/Pillow** - Image processing
- **pypdf** - PDF document processing
- **python-docx** - DOCX document processing

### **Performance Optimizations**
- **Lazy Loading** - Models loaded only when needed
- **Model Caching** - HuggingFace cache management
- **CPU Acceleration** - MKL, OpenBLAS, Intel optimizations
- **Memory Management** - Efficient tokenization and batching

---

## ğŸ¯ **Design Principles**

### **1. Modularity**
- **Separation of Concerns** - CLI, Client, Server are independent
- **Plugin Architecture** - Context Provider Commands are extensible
- **Interface Consistency** - Common patterns across all components

### **2. Privacy First**
- **Local Execution** - All model processing happens locally
- **No External APIs** - No data sent to external services
- **Offline Capable** - Works without internet after model download

### **3. Polish Language Focus**
- **Native Polish Support** - Optimized for Polish conversations
- **Cultural Context** - Understanding of Polish context and nuances
- **Speakleash Integration** - Direct access to Speakleash models

### **4. Developer Experience**
- **Simple APIs** - Easy-to-use Python interfaces
- **Comprehensive Documentation** - Detailed guides and examples
- **Testing Framework** - Docker-based multiplatform testing
- **Type Safety** - Full type hints and mypy compatibility

---

## ğŸ”„ **Extension Points**

### **1. Context Provider Commands**
Create custom commands by implementing `ContextProviderCommand`:
```python
class MyCommand(ContextProviderCommand):
    name = "mycommand"
    is_context_provider = True
    
    def provide_context(self, args: List[str], context: Dict[str, Any]) -> Dict[str, Any]:
        # Your logic here
        return {"type": "custom", "data": "processed"}
```

### **2. Model Backends**
Extend model support by implementing model runners:
```python
class CustomModelRunner:
    def load_model(self, model_path: str):
        # Custom model loading
        pass
    
    def chat(self, messages: List[Dict[str, str]]) -> str:
        # Custom inference
        pass
```

### **3. Output Formatters**
Add custom output formatting:
```python
class CustomFormatter:
    def format_response(self, response: str, context: Dict) -> str:
        # Custom formatting logic
        return formatted_response
```

---

## ğŸ›¡ï¸ **Security Architecture**

### **Data Protection**
- âœ… **Local Processing** - No external API calls
- âœ… **Sandboxed Execution** - Context Provider Commands run safely
- âœ… **Input Validation** - All user inputs validated and sanitized
- âœ… **Path Restrictions** - File access limited to safe directories

### **Model Security**
- âœ… **Verified Sources** - Only trusted HuggingFace models
- âœ… **Checksum Validation** - Model integrity verification
- âœ… **Safe Loading** - Secure model deserialization

### **Network Security**
- âœ… **HTTPS Downloads** - Secure model downloads from HF Hub
- âœ… **No Telemetry** - No usage data collection
- âœ… **Local Servers** - Web server binds to localhost only

---

## ğŸš€ **Performance Characteristics**

### **Startup Time**
- **Cold Start**: ~2-3 seconds (without model loading)
- **Model Loading**: ~10-30 seconds (first time, then cached)
- **Warm Start**: ~1 second (subsequent runs)

### **Memory Usage**
- **Base CLI**: ~50MB RAM
- **With 4.5B Model**: ~3-5GB RAM
- **With 7B Model**: ~6-8GB RAM
- **Context Provider Commands**: ~10-50MB RAM

### **Response Times**
- **Context Provider Commands**: <1 second
- **AI Responses**: 0.3-2 tokens/second (CPU), 10-50 tokens/second (GPU)
- **Model Switching**: ~5-15 seconds

---

## ğŸ”® **Future Architecture**

### **Planned Enhancements**
- **Plugin System** - Dynamic plugin loading and management
- **Distributed Models** - Support for model sharding and distribution
- **Advanced Caching** - Intelligent response caching and retrieval
- **Multi-language** - Support for additional languages beyond Polish

### **Scalability Considerations**
- **Horizontal Scaling** - Multiple server instances
- **Load Balancing** - Request distribution across models
- **Resource Management** - Dynamic resource allocation
- **Container Orchestration** - Kubernetes deployment support

---

**Next Steps:** [Usage Guide](USAGE.md) | [API Documentation](API.md) | [Context Providers](CONTEXT_PROVIDERS.md)
