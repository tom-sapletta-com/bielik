# ğŸ¦… bielik

[![PyPI](https://img.shields.io/pypi/v/bielik.svg)](https://pypi.org/project/bielik/)
[![Python](https://img.shields.io/pypi/pyversions/bielik.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Build](https://img.shields.io/github/actions/workflow/status/tomsapletta/bielik/python-app.yml?branch=main)](https://github.com/tomsapletta/bielik/actions)
[![Downloads](https://img.shields.io/pypi/dm/bielik.svg)](https://pypi.org/project/bielik/)
[![Code style: flake8](https://img.shields.io/badge/code%20style-flake8-black.svg)](https://flake8.pycqa.org/)
[![Issues](https://img.shields.io/github/issues/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/issues)
[![Stars](https://img.shields.io/github/stars/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/stargazers)
[![Forks](https://img.shields.io/github/forks/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/network)

**Author:** Tom Sapletta  
**License:** Apache-2.0

> ğŸ‡µğŸ‡± **Bielik** to lokalny klient chat do **[Ollama](https://ollama.com)** z interfejsem CLI i web, stworzony specjalnie dla polskiego modelu jÄ™zykowego **[Bielik](https://huggingface.co/speakleash)** od **[Speakleash](https://speakleash.org/)**.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          ğŸ¦… BIELIK                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ–¥ï¸  CLI Shell     â”‚  ğŸŒ FastAPI Server   â”‚  ğŸ§ª Test Suite   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Interactive   â”‚â”‚ â”‚ â€¢ REST /chat      â”‚ â”‚ â”‚ â€¢ Unit tests  â”‚ â”‚
â”‚  â”‚ â€¢ Help system   â”‚â”‚ â”‚ â€¢ WebSocket /ws   â”‚ â”‚ â”‚ â€¢ Mock API    â”‚ â”‚
â”‚  â”‚ â€¢ Cross-platformâ”‚â”‚ â”‚ â€¢ Port 8888       â”‚ â”‚ â”‚ â€¢ CI/CD       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                       â”‚                       â”‚
            â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ”„ CONNECTION LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚    REST API (main)   â”‚â—„â”€â”€â–ºâ”‚   Ollama Library (fallback) â”‚   â”‚
â”‚  â”‚ â”Œâ”€ HTTP requests     â”‚    â”‚ â”Œâ”€ ollama.chat()           â”‚   â”‚
â”‚  â”‚ â””â”€ /v1/chat/...     â”‚    â”‚ â””â”€ Direct integration      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ğŸ¦™ OLLAMA SERVER                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”‚ ğŸ“ localhost:11434 (default)                              â”‚
â”‚  â”‚ ğŸ¤– Model: bielik (Polish LLM)                             â”‚
â”‚  â”‚ ğŸ”— Links: Speakleash â†’ HuggingFace â†’ Ollama               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¤– About Bielik Model

**Bielik** to przeÅ‚omowy polski model jÄ™zykowy stworzony przez **[Speakleash](https://speakleash.org/)** - fundacjÄ™ zajmujÄ…cÄ… siÄ™ rozwojem polskiej sztucznej inteligencji.

### ğŸ”— External Dependencies & Links:
- **[Ollama](https://ollama.com)** - Local LLM runtime that hosts the Bielik model
- **[Bielik Model on HuggingFace](https://huggingface.co/speakleash)** - Official model repository
- **[Speakleash Foundation](https://speakleash.org/)** - Creators of the Bielik model
- **[Polish AI Initiative](https://www.gov.pl/web/ai)** - Government support for Polish AI

### ğŸš€ How it Works:
1. **Bielik package** connects to your local **Ollama server**
2. **Ollama** runs the **Bielik model** (downloaded from HuggingFace via Speakleash)
3. **Chat interface** (CLI/Web) sends queries â†’ **Ollama API** â†’ **Bielik model** â†’ responses
4. **Fallback system** ensures connectivity (REST API â†’ ollama library)

---

## ğŸ“Œ Features

- **ğŸ–¥ï¸ CLI** `bielik` â€” interactive chat shell with smart fallback system
- **ğŸŒ Web server** (FastAPI on port 8888):  
  - `POST /chat` â€” RESTful chat endpoint  
  - `WS /ws` â€” real-time WebSocket chat
- **ğŸ”„ Dual connectivity** â€” REST API primary, ollama lib fallback
- **ğŸ§ª Full test coverage** â€” unit tests with mocked APIs
- **ğŸ”§ Developer tools** â€” Makefile automation, CI/CD ready  

---

## âš™ï¸ Installation

```bash
pip install bielik
```

Optional dependency (official Ollama lib):

```bash
pip install "bielik[ollama]"
```

---

## ğŸš€ Usage

### CLI

```bash
bielik
```

Wpisz wiadomoÅ›ci, zakoÅ„cz `:exit`.

### Web API

```bash
uvicorn bielik.server:app --port 8888
```

* POST `/chat`:

```json
{"messages": [{"role":"user","content":"Hello!"}]}
```

* WebSocket `/ws`

---

## ğŸ”§ Environment Variables

* `OLLAMA_HOST` â€” default: `http://localhost:11434`
* `BIELIK_MODEL` â€” default: `bielik`

---

## ğŸ“ Development

```bash
git clone https://github.com/tomsapletta/bielik.git
cd bielik
python -m venv .venv
source .venv/bin/activate
pip install -e .[ollama]
```


# ğŸ“‚ Struktura

```
bielik/
â”œâ”€â”€ bielik/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â””â”€â”€ server.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli.py
â”‚   â””â”€â”€ test_server.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ setup.cfg
â”œâ”€â”€ MANIFEST.in
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â””â”€â”€ .github/workflows/python-publish.yml
```



## ğŸ“œ License

[Apache License 2.0](LICENSE)


