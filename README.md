# ğŸ¦… Bielik

[![PyPI](https://img.shields.io/pypi/v/bielik.svg)](https://pypi.org/project/bielik/)
[![Python](https://img.shields.io/pypi/pyversions/bielik.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](LICENSE)
[![Build](https://img.shields.io/github/actions/workflow/status/tomsapletta/bielik/python-app.yml?branch=main)](https://github.com/tomsapletta/bielik/actions)
[![Downloads](https://img.shields.io/pypi/dm/bielik.svg)](https://pypi.org/project/bielik/)
[![Code style: flake8](https://img.shields.io/badge/code%20style-flake8-black.svg)](https://flake8.pycqa.org/)
[![Issues](https://img.shields.io/github/issues/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/issues)
[![Stars](https://img.shields.io/github/stars/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/stargazers)
[![Forks](https://img.shields.io/github/forks/tomsapletta/bielik.svg)](https://github.com/tomsapletta/bielik/network)

**Author:** Tom Sapletta  
**License:** Apache-2.0

> ğŸ‡µğŸ‡± **Bielik** is a powerful Polish AI Assistant that downloads and runs **[Polish language models](https://huggingface.co/speakleash)** from **[HuggingFace](https://huggingface.co)**, created specifically for the **[Bielik](https://huggingface.co/speakleash)** models from **[Speakleash](https://speakleash.org/)**.

**ğŸš€ Key Features:**
- ğŸ¯ **HuggingFace Integration** - Direct model downloads from HF Hub
- ğŸ’¬ **Polish Language Optimized** - Built for Polish conversation and analysis  
- ğŸ–¼ï¸ **Vision Capabilities** - Image analysis and visual question answering
- ğŸ“ **Document Processing** - PDF, DOCX, web content analysis
- ğŸ³ **Docker Ready** - Containerized testing environments
- âš¡ **Lightweight** - Minimal (~50MB) or Full (~2GB) installation options

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ¦… BIELIK SYSTEM                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   ğŸ–¥ï¸  CLI Shell     â”‚  ğŸŒ FastAPI Server   â”‚  ğŸ³ Docker Tests   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ â€¢ Interactive   â”‚â”‚ â”‚ â€¢ REST /chat      â”‚ â”‚ â”‚ â€¢ Minimal     â”‚ â”‚
â”‚  â”‚ â€¢ Personalized  â”‚â”‚ â”‚ â€¢ WebSocket /ws   â”‚ â”‚ â”‚ â€¢ Full        â”‚ â”‚
â”‚  â”‚ â€¢ Multi-modal   â”‚â”‚ â”‚ â€¢ Port 8000       â”‚ â”‚ â”‚ â€¢ CI/CD       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                       â”‚                       â”‚
            â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ğŸ¤— HUGGINGFACE INTEGRATION                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Direct Downloads   â”‚â—„â”€â”€â–ºâ”‚     Local Model Execution   â”‚  â”‚
â”‚  â”‚ â”Œâ”€ HF Hub API        â”‚    â”‚ â”Œâ”€ Transformers Pipeline    â”‚  â”‚
â”‚  â”‚ â””â”€ Model Management  â”‚    â”‚ â””â”€ Vision Models (optional) â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 ğŸ“š POLISH LANGUAGE MODELS                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ¤– Speakleash/Bielik Models (HuggingFace Hub)          â”‚  â”‚
â”‚  â”‚ ğŸ”— Direct: HuggingFace â†’ Local Storage â†’ Execution     â”‚  â”‚
â”‚  â”‚ ğŸ¯ Polish-optimized conversation and analysis          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

![terminal](terminal.png)

## ğŸ¤– About Bielik Model

**Bielik** is a groundbreaking Polish language model created by **[Speakleash](https://speakleash.org/)** - a foundation dedicated to the development of Polish artificial intelligence.

### ğŸ”— External Dependencies & Links:
- **[HuggingFace Hub](https://huggingface.co)** - Primary source for Polish language models
- **[Bielik Models on HuggingFace](https://huggingface.co/speakleash)** - Official model repository
- **[Speakleash Foundation](https://speakleash.org/)** - Creators of the Bielik models
- **[Polish AI Initiative](https://www.gov.pl/web/ai)** - Government support for Polish AI

### ğŸš€ How it Works:
1. **Bielik CLI** connects directly to **HuggingFace Hub**
2. **Models** are downloaded from **Speakleash** organization on HuggingFace
3. **Local execution** uses **Transformers** library (optional for vision)
4. **Chat interface** (CLI/Web) â†’ **Local Models** â†’ **Polish responses**
5. **Modular design** supports text-only or full vision capabilities

---

## ğŸ“Œ Features

- **ğŸ¯ HuggingFace Integration** â€” Direct model downloads and management
  - **ğŸ” Model Discovery** â€” Browse available Polish language models
  - **ğŸ“¦ Smart Downloads** â€” Automatic model caching and versioning
  - **ğŸš€ Auto-Switch** â€” Automatically switches to newly downloaded models
  - **ğŸ› ï¸ Interactive** â€” User-friendly model selection on first startup
- **ğŸ–¥ï¸ Enhanced CLI** `python -m bielik` â€” Personalized chat experience
  - **ğŸ“‹ Commands** â€” `:help`, `:models`, `:download`, `:delete`, `:switch`, `:settings`, `:name`
  - **âš™ï¸ Personalization** â€” Custom user names, dynamic assistant names
  - **ğŸ¤— HF Management** â€” Direct HuggingFace model operations
  - **ğŸ“ Content Analysis** â€” Folder scanning, document processing
  - **ğŸŒ Cross-platform** â€” Windows, macOS, Linux support
- **ğŸ–¼ï¸ Vision Capabilities** (Full version only)
  - **ğŸ” Image Analysis** â€” Automatic image captioning in Polish
  - **â“ Visual QA** â€” Ask questions about images
  - **ğŸ¨ Multi-modal** â€” Combined text and image understanding
  - **âš¡ GPU Support** â€” Hardware acceleration for faster processing
- **ğŸ Python API** â€” Programmatic access via `BielikClient` class
  - **ğŸ’¬ Chat methods** â€” `chat()`, `query()`, conversation management
  - **ğŸ”§ Model control** â€” Download, switch, and manage models
  - **ğŸ¤— HF Models** â€” Full HuggingFace integration
  - **ğŸ“¤ Export** â€” Conversation history in multiple formats
- **ğŸŒ Web Server** (FastAPI on port 8000):  
  - **ğŸ“¡ REST** â€” `POST /chat` endpoint for JSON communication
  - **âš¡ WebSocket** â€” `WS /ws` for real-time chat
  - **ğŸ–¼ï¸ Multi-modal** â€” Support for text and image inputs
- **ğŸ³ Docker Support** â€” Complete containerized testing
  - **ğŸ“¦ Minimal Version** â€” Lightweight text-only container (~50MB)
  - **ğŸ¯ Full Version** â€” Complete vision-enabled container (~2GB)
  - **ğŸ”§ CI/CD** â€” Automated testing environments  

---

## âš™ï¸ Installation Options

Bielik offers **two installation modes** to suit different needs:

### ğŸª¶ **Minimal Version** (Recommended for most users)

**~50MB installation** - Perfect for text-based Polish AI conversations:

```bash
# Install minimal version (text-only)
pip install bielik

# Start CLI and download your first model
python -m bielik
```

**What's included:**
- âœ… Polish conversation and text analysis
- âœ… HuggingFace model downloads and management  
- âœ… Document processing (PDF, DOCX, TXT)
- âœ… Web content analysis
- âœ… Folder structure analysis
- âœ… Personalized CLI experience
- âŒ Image analysis (can be added later)

### ğŸ¯ **Full Version** (For image analysis)

**~2GB+ installation** - Complete AI assistant with vision capabilities:

```bash
# Install full version (text + vision)
pip install bielik[vision]

# Start CLI with image analysis support
python -m bielik
```

**What's included:**
- âœ… **Everything from minimal version**
- âœ… **Image analysis and captioning**
- âœ… **Visual question answering**
- âœ… **GPU acceleration support**
- âœ… **Multi-modal document processing**

### ğŸ”„ **Upgrade Anytime**

Start minimal and upgrade when needed:

```bash
# Upgrade minimal â†’ full
pip install bielik[vision]

# Or install specific optional features
pip install bielik[local]    # Local model execution
pip install bielik[gpu]      # GPU acceleration
pip install bielik[dev]      # Development tools
```

---

## ğŸš€ Quick Start Guide

### ğŸ¯ **Instant Start** (No setup required!)

Bielik now works **without any external dependencies**. Just install and start chatting:

```bash
# Install minimal version
pip install bielik

# Start CLI and choose your first model
python -m bielik
```

**What happens on first run:**
- ğŸ” **Model Selection** â€” Choose from available Polish models
- ğŸ“¥ **Auto Download** â€” Selected model downloads from HuggingFace
- ğŸ”„ **Auto Switch** â€” Automatically switches to the new model
- ğŸ’¬ **Ready to Chat** â€” Start conversing in Polish immediately!

### ğŸ“± **Choose Your Experience**

#### ğŸª¶ **Minimal Setup** (Recommended)
Perfect for text conversations and document analysis:
```bash
# 1. Install
pip install bielik

# 2. Start and download your first model
python -m bielik
:download speakleash/bielik-4.5b-v3.0-instruct

# 3. Start chatting in Polish!
CzeÅ›Ä‡! Jak mogÄ™ Ci pomÃ³c?
```

#### ğŸ¯ **Full Setup** (For image analysis)
Includes vision capabilities for image analysis:
```bash
# 1. Install with vision support
pip install bielik[vision]

# 2. Start and download models
python -m bielik
:download speakleash/bielik-4.5b-v3.0-instruct

# 3. Analyze images
Przeanalizuj to zdjÄ™cie: image.jpg
```

#### ğŸ³ **Docker Setup** (For testing)
Use Docker for isolated testing environments:
```bash
# Clone repository
git clone https://github.com/tomsapletta/bielik.git
cd bielik

# Test minimal version
docker-compose --profile minimal up bielik-minimal

# Test full version  
docker-compose --profile full up bielik-full
```

---

## ğŸ’» Usage

### ğŸ–¥ï¸ CLI Commands & Options

#### Starting Bielik

```bash
# Basic usage
python -m bielik                         # Start interactive chat
bielik                                   # Alternative (if in PATH)

# Advanced options  
python -m bielik --help                  # Show all options
```

#### Interactive Commands (inside chat session)

**ğŸ“‹ Model Management:**
```bash
:models                    # List available HuggingFace models
:download <model-name>     # Download model from HuggingFace
:switch <model-name>       # Switch to downloaded model
:delete <model-name>       # Delete model from local storage
```

**âš™ï¸ Personalization:**
```bash
:name <your-name>          # Set your display name
:settings                  # Show current configuration
```

**ğŸ› ï¸ Utilities:**
```bash
:help                      # Show all commands
:clear                     # Clear conversation history
:exit                      # Quit (or Ctrl+C)
```

#### Usage Examples

**First Time Setup:**
```bash
$ python -m bielik
# Choose from recommended models:
# 1. speakleash/bielik-4.5b-v3.0-instruct (Recommended)
# 2. speakleash/bielik-7b-instruct-v0.1
# Enter choice: 1

ğŸ”„ Downloading speakleash/bielik-4.5b-v3.0-instruct...
âœ… Model ready! Switching to bielik-4.5b-v3.0-instruct

ğŸ‘¤ You: CzeÅ›Ä‡! Jak siÄ™ masz?
ğŸ¤– bielik-4.5b: CzeÅ›Ä‡! Mam siÄ™ dobrze, dziÄ™kujÄ™...
```

**Everyday Usage:**
```bash
ğŸ‘¤ You: :name Jan
âœ… Display name set to: Jan

ğŸ‘¤ Jan: Przeanalizuj folder ~/dokumenty
ğŸ¤– bielik-4.5b: [Analyzes folder structure and contents]

ğŸ‘¤ Jan: Opisz to zdjÄ™cie: vacation.jpg  # (Full version only)
ğŸ¤– bielik-4.5b: [Describes image in Polish]
```

### ğŸ Python API

Use Bielik programmatically in your Python applications:

```python
from bielik.client import BielikClient

# Create client (auto-downloads model if needed)
client = BielikClient()

# Send a Polish message
response = client.chat("Napisz krÃ³tki wiersz o Polsce")
print(response)

# Get model status
status = client.get_status()
print(f"Current model: {status['current_model']}")
print(f"Models available: {status['models_available']}")

# Export conversation
history = client.export_conversation(format="markdown")
```

**Quick functions:**
```python
from bielik.client import quick_chat

# One-off Polish query
response = quick_chat("Co to jest sztuczna inteligencja?")
print(response)
```

**BielikClient Options:**
- `model`: Specific HuggingFace model to use
- `auto_download`: Auto-download model if missing (default: True)

### ğŸŒ Web Server

```bash
# Start web server
uvicorn bielik.server:app --port 8000

# Or with Docker
docker-compose --profile minimal up bielik-minimal
```

**Endpoints:**
- `POST /chat` - JSON chat endpoint
- `WS /ws` - WebSocket real-time chat
- `GET /models` - List available models

**Example request:**
```json
{"messages": [{"role":"user","content":"CzeÅ›Ä‡! Jak siÄ™ masz?"}]}
```

### ğŸ³ Docker Usage

**Quick Testing:**
```bash
# Test minimal version
docker run -it bielik:minimal

# Test full version with GPU
docker run --gpus all -it bielik:full
```

**With persistent storage:**
```bash
# Minimal with model persistence
docker run -it -v $(pwd)/models:/app/models bielik:minimal

# Full with models and images
docker run -it \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/images:/app/images \
  bielik:full
```

**Development setup:**
```bash
# Clone and test
git clone https://github.com/tomsapletta/bielik.git
cd bielik

# Run automated tests
docker-compose --profile test up test-runner

# Interactive development
docker-compose --profile minimal run --rm bielik-minimal bash
```

---

## ğŸ”§ Environment Variables

**Core Settings:**
* `BIELIK_CLI_USERNAME` â€” Your display name in CLI (auto-detected from system)
* `BIELIK_CLI_CURRENT_MODEL` â€” Currently selected model
* `BIELIK_CLI_ASSISTANT_NAME` â€” Assistant display name (auto-set from model)
* `BIELIK_CLI_AUTO_SWITCH` â€” Auto-switch to newly downloaded models (default: true)

**Storage & Cache:**
* `BIELIK_MODELS_DIR` â€” Local model storage directory
* `BIELIK_DATA_DIR` â€” User data and settings directory
* `HF_HOME` â€” HuggingFace cache directory

**Docker Environment:**
* `BIELIK_MODE` â€” `minimal` or `full` (Docker only)
* `BIELIK_IMAGES_DIR` â€” Images directory for analysis (full version)

---

## ğŸ› ï¸ Troubleshooting

### Installation Issues

**Problem:** Minimal version works but vision features don't
```bash
# Upgrade to full version
pip install bielik[vision]

# Verify vision packages
python -c "import PIL, transformers; print('Vision packages OK')"
```

**Problem:** Model download fails or times out
```bash
# Check HuggingFace connectivity
python -c "from huggingface_hub import HfApi; print('HF connection OK')"

# Check available disk space (models are 2-8GB)
df -h

# Manual download with timeout
:download speakleash/bielik-4.5b-v3.0-instruct
```

**Problem:** "No models available" on first startup
```bash
# Download a model manually
python -m bielik
:models
:download speakleash/bielik-4.5b-v3.0-instruct
```

### Runtime Issues

**Problem:** Model responses are slow or use too much memory
```bash
# Use smaller model
:switch speakleash/bielik-4.5b-v3.0-instruct  # instead of 7b

# Check system resources
htop      # Linux/macOS
taskmgr   # Windows

# Enable GPU acceleration (full version)
pip install bielik[gpu]
```

**Problem:** Image analysis not working
```bash
# Check if vision packages installed
python -c "from bielik.image_analyzer import ImageAnalyzer; ia = ImageAnalyzer(); print(f'Available: {ia.is_available()}')"

# Install vision support
pip install bielik[vision]
```

**Problem:** CLI settings not persisting
```bash
# Check .env file creation
ls -la ~/.bielik/ || ls -la ./

# Reset settings
:name YourName
:settings
```

### Docker Issues

**Problem:** Docker containers fail to start
```bash
# Build images manually
docker build -f docker/Dockerfile.minimal -t bielik:minimal .
docker build -f docker/Dockerfile.full -t bielik:full .

# Check container logs
docker logs bielik-minimal
```

**Problem:** Models not persisting between Docker runs
```bash
# Use volume mounts
docker run -v $(pwd)/models:/app/models bielik:minimal

# Or use Docker Compose
docker-compose --profile minimal up
```

### Getting Help

- **GitHub Issues:** [Report bugs and feature requests](https://github.com/tomsapletta/bielik/issues)
- **Command Help:** `python -m bielik --help` or `:help` in CLI
- **Test Environment:** Use Docker for isolated testing
- **Check Status:** Use `:settings` command for current configuration

---

## ğŸ“ Development

```bash
git clone https://github.com/tomsapletta/bielik.git
cd bielik
python -m venv .venv
source .venv/bin/activate
pip install -e .[ollama]
```


# ğŸ“‚ Package Structure

```
bielik/
â”œâ”€â”€ bielik/
â”‚   â”œâ”€â”€ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ cli.py               # CLI entry point (wrapper)
â”‚   â”œâ”€â”€ client.py            # Client entry point (wrapper)
â”‚   â”œâ”€â”€ server.py            # FastAPI web server
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ hf_models.py         # Hugging Face model management
â”‚   â”œâ”€â”€ content_processor.py # Content processing utilities
â”‚   â”œâ”€â”€ cli/                 # Modular CLI components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py          # Main CLI entry and argument parsing
â”‚   â”‚   â”œâ”€â”€ commands.py      # Command processing and execution
â”‚   â”‚   â”œâ”€â”€ models.py        # HF model management CLI
â”‚   â”‚   â”œâ”€â”€ setup.py         # Interactive setup manager
â”‚   â”‚   â””â”€â”€ send_chat.py     # Chat communication handling
â”‚   â””â”€â”€ client/              # Modular client components
â”‚       â”œâ”€â”€ __init__.py      # Client package exports
â”‚       â”œâ”€â”€ core.py          # Core BielikClient class
â”‚       â”œâ”€â”€ model_manager.py # HF model operations for client
â”‚       â””â”€â”€ utils.py         # Client utility functions
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli.py          # CLI unit tests
â”‚   â””â”€â”€ test_server.py       # Server unit tests
â”œâ”€â”€ pyproject.toml           # Modern Python packaging
â”œâ”€â”€ setup.cfg                # Package configuration
â”œâ”€â”€ MANIFEST.in              # Package manifest
â”œâ”€â”€ LICENSE                  # Apache 2.0 license
â”œâ”€â”€ README.md                # This documentation
â”œâ”€â”€ Makefile                 # Development automation
â”œâ”€â”€ todo.md                  # Project specifications
â””â”€â”€ .github/workflows/       # CI/CD automation
    â””â”€â”€ python-publish.yml
```



## ğŸ“œ License

[Apache License 2.0](LICENSE)


